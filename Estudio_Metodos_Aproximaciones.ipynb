{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c04a971",
   "metadata": {},
   "source": [
    "# Estudio de métodos de control con aproximaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb903893",
   "metadata": {},
   "source": [
    "Este estudio pertenece a la parte 2 de la práctica 1 correspondiente a la asignatura Extensiones de Machine Learning del máster de IA en la Universidad de Murcia.\n",
    "\n",
    "El grupo de alumnos que han realizado el estudio está conformado por:\n",
    "\n",
    "- Tomás Díaz Díaz\n",
    "- Jose Antonio Sánchez Fernández"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503bb053",
   "metadata": {},
   "source": [
    "## Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fbae2b",
   "metadata": {},
   "source": [
    "Este notebook explora técnicas de aprendizaje por refuerzo que requieren aproximación de funciones:\n",
    "- SARSA semi-gradiente\n",
    "- Deep Q-Learning (DQN)\n",
    "\n",
    "Para la realización del estudio, se utilizará el entorno ***Gymnasium***. Ambas técnicas serán evaluadas en el escenario `CartPole-v1`, consistente en un carro que debe mantener una barra en equilibrio mediante el movimento a izquierda. El espacio de estados en este escenario es continuo y el espacio de acciones es discreto, como veremos durante la creación del entorno. Cada episodio del experimento termina cuando la barra cae o transcurren 500 pasos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "526f8064",
   "metadata": {},
   "source": [
    "## Imports y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8b8e4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gymnasium as gym\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import sys\n",
    "sys.path.append('src/')\n",
    "from AgentSARSASemiGradiente import AgentSARSASemiGradiente\n",
    "from AgentDeepQLearning import QNetwork, AgentDQLearning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c13d65d",
   "metadata": {},
   "source": [
    "## Preparación del entorno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce12bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estado: 4 dimensiones, Acciones: 2\n",
      "Dimensiones: Box([-4.8               -inf -0.41887903        -inf], [4.8               inf 0.41887903        inf], (4,), float32)\n"
     ]
    }
   ],
   "source": [
    "# Declaramos una semilla para la reproducibilidad de los resultados y modificación del entorno CartPole\n",
    "SEMILLA = 42\n",
    "env = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\")\n",
    "# TODO Posible sustitución por un Wrapper para observar mejor las dimensiones del entorno\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n\n",
    "print(f\"Estado: {state_dim} dimensiones, Acciones: {action_dim}\")\n",
    "print(f\"Dimensiones: {env.observation_space}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85bc4eb1",
   "metadata": {},
   "source": [
    "**¿Qué estamos viendo en este entorno?**\n",
    "\n",
    "Lo que nos dice esta salida de las características del entorno es que disponemos de 4 dimensiones basadas en las variables que influyen en la localización espacial del carrito, y 2 acciones que podemos realizar con él.\n",
    "Sobre las dimensiones, por la documentación del escenario concreto, sabemos que consisten en las siguientes:\n",
    "\n",
    "| Dimensión                    | Rango mostrado                 | Límites mostrados               | Tipo de dato |\n",
    "|------------------------------|--------------------------------|---------------------------------|--------------|\n",
    "| Posición del carrito (x)     | [-4.8, 4.8]                    | [-4.8, 4.8]                     | `float32`    |\n",
    "| Velocidad del carrito (v)    | No acotado (realmente es ±20)  | [-inf, inf]                     | `float32`    |\n",
    "| Ángulo del poste en radianes | [-0.418, 0.418] (~±24°)        | [-0.41887903, 0.41887903]       | `float32`    |\n",
    "| Velocidad angular del poste  | No acotado (realmente es ±50)  | [-inf, inf]                     | `float32`    |\n",
    "\n",
    "Estas dimensiones son las que influyen en la cantidad de estados de los que dispondrán nuestros agentes para moverse y alcanzar una política. Sin embargo, al haber variables sin un rango discreto, vemos que habrá una cantidad infinita de estados, por lo que los métodos tabulares dejan de ser viables en un escenario como este. Es por ello que utilizaremos este entorno para demostrar la funcionalidad de los métodos de control por aproximaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4d1a95",
   "metadata": {},
   "source": [
    "## Creación de agentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298f508",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa_agent = AgentSARSASemiGradiente(env, SEMILLA, alpha=0.1, gamma=0.99, epsilon=0.1, n_episodes=1000)\n",
    "\n",
    "dql_agent = AgentDQLearning(env, SEMILLA, alpha=0.1, gamma=0.99, epsilon=0.1, n_episodes=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd04883f",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cd3835",
   "metadata": {},
   "outputs": [],
   "source": [
    "sarsa_agent.train()\n",
    "dql_agent.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257baa49",
   "metadata": {},
   "source": [
    "## Evaluación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f94d915",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Graficas recompensas por episodio, rendimiento promedio\n",
    "# Disponibles en http://gymnasium.farama.org/introduction/train_agent/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264a6224",
   "metadata": {},
   "source": [
    "## Análisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d486e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Mostrar diferencias en rendimiento y comportamiento"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gym_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
